{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Feature Engineering\n",
    "\n",
    "This notebook focuses on creating features from:\n",
    "1. Technical indicators from stock price data\n",
    "2. Sentiment analysis from news data\n",
    "3. Feature selection and dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.features.technical_indicators import calculate_technical_indicators\n",
    "from src.features.sentiment_features import extract_sentiment_features\n",
    "from src.features.feature_reduction import select_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Preprocessed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'GOOG', 'MSFT']\n",
    "stock_data = {}\n",
    "news_data = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    stock_data[symbol] = pd.read_csv(f'../data/preprocessed/{symbol}_stock_preprocessed.csv', index_col=0, parse_dates=True)\n",
    "    news_data[symbol] = pd.read_csv(f'../data/preprocessed/{symbol}_news_preprocessed.csv', parse_dates=['date'])\n",
    "    print(f\"Loaded data for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    # Moving averages\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    \n",
    "    # Relative Strength Index\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_upper'] = df['BB_middle'] + 2 * df['Close'].rolling(window=20).std()\n",
    "    df['BB_lower'] = df['BB_middle'] - 2 * df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "technical_data = {}\n",
    "for symbol in symbols:\n",
    "    technical_data[symbol] = add_technical_indicators(stock_data[symbol].copy())\n",
    "    print(f\"Added technical indicators for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract Sentiment Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def calculate_sentiment_scores(df):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Calculate sentiment scores\n",
    "    df['vader_compound'] = df['text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "    df['textblob_polarity'] = df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    \n",
    "    # Group by date and calculate daily sentiment metrics\n",
    "    daily_sentiment = df.groupby('date').agg({\n",
    "        'vader_compound': ['mean', 'std', 'count'],\n",
    "        'textblob_polarity': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    return daily_sentiment\n",
    "\n",
    "sentiment_data = {}\n",
    "for symbol in symbols:\n",
    "    sentiment_data[symbol] = calculate_sentiment_scores(news_data[symbol])\n",
    "    print(f\"Calculated sentiment scores for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Combine Features and Create Target Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_final_features(technical_df, sentiment_df):\n",
    "    # Merge technical and sentiment features\n",
    "    combined_df = technical_df.join(sentiment_df)\n",
    "    \n",
    "    # Create target variable (1 if price goes up, 0 if down)\n",
    "    combined_df['target'] = (combined_df['Close'].shift(-1) > combined_df['Close']).astype(int)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    combined_df = combined_df.dropna()\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    feature_columns = [col for col in combined_df.columns if col != 'target']\n",
    "    combined_df[feature_columns] = scaler.fit_transform(combined_df[feature_columns])\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "final_datasets = {}\n",
    "for symbol in symbols:\n",
    "    final_datasets[symbol] = prepare_final_features(technical_data[symbol], sentiment_data[symbol])\n",
    "    print(f\"Prepared final features for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Selection and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def select_important_features(df, k=15):\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    # Select top k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    \n",
    "    # Create new dataframe with selected features\n",
    "    return df[selected_features + ['target']], selected_features\n",
    "\n",
    "# Apply feature selection to each dataset\n",
    "selected_datasets = {}\n",
    "selected_features = {}\n",
    "for symbol in symbols:\n",
    "    selected_datasets[symbol], selected_features[symbol] = select_important_features(final_datasets[symbol])\n",
    "    print(f\"\\nSelected features for {symbol}:\")\n",
    "    print(selected_features[symbol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Engineered Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final processed datasets\n",
    "for symbol in symbols:\n",
    "    selected_datasets[symbol].to_csv(f'../data/preprocessed/{symbol}_final_features.csv')\n",
    "    print(f\"Saved final features for {symbol}\")\n",
    "\n",
    "# Save selected feature lists for use in model training\n",
    "import json\n",
    "with open('../data/preprocessed/selected_features.json', 'w') as f:\n",
    "    json.dump(selected_features, f)\n",
    "print(\"Saved selected features list\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
